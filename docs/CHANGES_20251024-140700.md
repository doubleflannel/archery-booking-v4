## CHANGES: Faster Target Tracking Pipeline

This change replaces “heavy feature match every frame” with a fast
track-and-refresh loop, and restricts expensive work to a smart Region of
Interest (ROI).

### Summary
- Previously: Run SIFT + BF match on every frame, then `findHomography`.
- Now: Do one solid detection to lock a homography H0, then track a small set
  of points with Lucas–Kanade (LK) optical flow and refit a lightweight
  transform each frame. If tracking confidence drops, briefly re-detect.
- Also: Only detect/match inside an ROI around the last known target location
  (expand by ~10–15%).

### 1) Bootstrapped homography → fast tracking
- Initial lock
  - Detect features (SIFT/ORB) and match to template/reference.
  - Estimate homography H0 with RANSAC; require ≥4 inliers and a sane
    reprojection error threshold (e.g., 2–4 px).
- Track between frames (cheap)
  - Seed N well-spaced points (e.g., `cv2.goodFeaturesToTrack` or corners of the
    warped target). Recommended: 40–80 points; min spacing 8–12 px.
  - Track with `cv2.calcOpticalFlowPyrLK` using a pyramid: `winSize=(21,21)`,
    `maxLevel=3`, `criteria=(COUNT=30, EPS=0.01)`.
  - Filter to valid tracks by LK `status==1` and low tracking error.
- Refit a small transform
  - If perspective changes matter: `cv2.findHomography(prev_pts, curr_pts, RANSAC, 3.0)`.
  - If the camera is mostly fixed: use similarity/affine for stability and speed:
    `cv2.estimateAffinePartial2D` (scale + rotation + translation) or even just
    translation.
  - Compose with prior: `H_t = H_inc ∘ H_{t-1}` (or keep affine directly if
    downstream accepts it). Consider a light temporal smooth (e.g., EMA) to
    reduce jitter.
- Confidence and drift control
  - Confidence = valid_tracks / total_tracks, median LK error, and/or median
    symmetric transfer error after refit.
  - If confidence < threshold (e.g., <0.5 or <12 good points) or error too high,
    fall back to a re-detect (see Fallback).
  - Periodically re-seed points on the current warped target to avoid point
    depletion; keep target coverage.

### 2) “I already know where it was” ROI
- Maintain ROI from last known target pose: use the quadrilateral from warping
  the template corners by H_t; take its bounding box or convex hull.
- Expand ROI by ~10–15% margin to absorb small motion.
- Restrict heavy ops to ROI
  - Keypoint detection: pass an ROI mask to SIFT/ORB or use `goodFeaturesToTrack`
    with a mask.
  - Descriptor extraction and matching: only for keypoints inside ROI.
- Benefit: slashes the number of keypoints and matches to consider, often
  reducing compute by 5–15× versus full-frame.

### Fallback and reacquire
- If tracking degrades:
  - Try a feature detection + match inside the current ROI first.
  - If that fails, expand ROI or do a global pass as a last resort.
- On success, set new H0 and resume fast tracking.

### Suggested parameters (starting points)
- LK: `winSize=(21,21)`, `maxLevel=3`, `criteria=(COUNT=30, EPS=0.01)`.
- RANSAC: reprojection threshold ~3.0 px, `confidence=0.995`.
- Points: 40–80 well-spaced; re-seed when <60% remain or coverage is poor.
- ROI margin: 10–15% beyond last pose bounds.

### Pseudocode sketch
```python
# On first robust detection
H = H0_from_sift_orb_ransac(frame, template)
pts_ref = sample_points_on_template(template, N=60)
pts_prev = warp_points(pts_ref, H)

for frame in video_stream:
    # Track
    pts_curr, status, err = cv2.calcOpticalFlowPyrLK(prev_frame, frame, pts_prev, None, ...)
    good_prev = pts_prev[status==1]
    good_curr = pts_curr[status==1]

    if len(good_curr) >= 12:
        # Refit (homography or affine/similarity)
        H_inc, inliers = cv2.findHomography(good_prev, good_curr, cv2.RANSAC, 3.0)
        if H_inc is not None:
            H = H_inc @ H
            # Optionally smooth H
            # Re-seed occasionally from current warped target
        else:
            # fallback
            H = reacquire(frame, ROI_from(H))
            pts_prev = warp_points(pts_ref, H)
    else:
        # fallback
        H = reacquire(frame, ROI_from(H))
        pts_prev = warp_points(pts_ref, H)

    prev_frame = frame
    pts_prev = good_curr if len(good_curr) else warp_points(pts_ref, H)
```

### NYC 10‑year‑old analogy
- Big search once, then follow: First you find your favorite pizza shop using a
  big city map (that’s the heavy SIFT+BF step). After that, you just follow a
  few friends walking from block to block (those are the LK-tracked points). If
  you lose them in the crowd, you check the map again.
- Look where you last saw it: Don’t scan the whole city every time. Keep your
  eyes on the same neighborhood where the pizza shop was, maybe one block
  bigger. Much faster, less wandering.

### Expected effect
- Heavy “detect + match + homography” runs only occasionally.
- Per-frame cost dominated by LK tracking and a small refit ⇒ significant FPS
  increase, lower CPU/GPU load, and lower latency.

